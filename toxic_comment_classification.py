# -*- coding: utf-8 -*-
"""toxic-comment-classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3YfjuBCq2z52D-iorzDg_GlCGcWiq7y
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import os
import pandas as pd
import tensorflow as tf

!pip install mlflow

!databricks configure --host https://community.cloud.databricks.com/
import mlflow
mlflow.set_tracking_uri("databricks")
mlflow.set_experiment("/Users/desmondstha125@gmail.com/toxic_comment_classification")

"""Loading data from drive"""

train = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/jigsaw-toxic-comment-classification-challenge/train.csv/train.csv")
testText = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/jigsaw-toxic-comment-classification-challenge/test.csv/test.csv')
testLevel = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/jigsaw-toxic-comment-classification-challenge/test_labels.csv/test_labels.csv")

print("Shape of train data: ", train.shape)
print("Shape of test data: ", testText.shape)

testText.head()

testLevel.head()

test = pd.merge(testText,testLevel, on='id')
test = test[test['toxic']!=-1]
test.head()

train.describe()

"""Visualzing the data"""

import seaborn as sns
import matplotlib.pyplot as plt

# sns.set(color_codes=True)
comment_len = train.comment_text.str.len()
sns.distplot(comment_len,kde=False, color="blue")
plt.xlim(0, 2500)

plt.xlabel('Comment Length')

# Display the plot
plt.show()

"""We can see most of the comments have short length and very few have length grater than 1000

Plotting the correlational matrix
"""

rowsums = train.iloc[:, 2:8].sum(axis=1)
temp = train.iloc[:, 2:8]
train_corr = temp[rowsums > 0]
corr = train_corr.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(corr,
            xticklabels=corr.columns.values,
            yticklabels=corr.columns.values, annot=True, cmap="Blues")

"""The highest levels of correlation can
be observed between the obscene and toxic

Preprocessing the data

1.   Removing Characters in between Text.
2. Removing Repeated Characters.

1.   Converting data to lower-case.
2.   Removing Punctuation.
3.   Removing unnecessary white spaces in between words.
2.   Removing “\n”.
3. Removing Non-English characters.
"""

import re

def clean_text(text,remove_repeat_text=True, is_lower=True):

  if is_lower:
    text=text.lower()

  if remove_repeat_text:
    text = re.sub(r'(.)\1{2,}', r'\1', text)  #removes repeated characters.
    # uses regular expressions (re) to find consecutive occurrences of a character
    # and replaces them with a single instance of that character.
    # For example, it replaces "loooove" with "love" by reducing consecutive repeated characters to a single occurrence

  text = str(text).replace("\n", " ") #replaces newline characters (\n) with a space character
  text = re.sub(r'[^\w\s]',' ',text) #substitute any non-alphanumeric and non-whitespace characters with a space character.
  text = re.sub('[0-9]',"",text) #remove any numeric digits from the text
  text = re.sub(" +", " ", text) #replace multiple consecutive spaces with a single space
  text = re.sub("([^\x00-\x7F])+"," ",text) #remove any non-ASCII characters from the text
  return text

train['comment_text'] = train['comment_text'].apply(clean_text)
test['comment_text'] = test['comment_text'].apply(clean_text)

"""Removing Stopwords using NLTK stopwords"""

import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')
print(stopwords.words('english'))

stop_words = set(stopwords.words('english'))
# stop_words = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', "you're", "you've", "you'll", "you'd", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', "she's", 'her', 'hers', 'herself', 'it', "it's", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', "that'll", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', "don't", 'should', "should've", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', "aren't", 'couldn', "couldn't", 'didn', "didn't", 'doesn', "doesn't", 'hadn', "hadn't", 'hasn', "hasn't", 'haven', "haven't", 'isn', "isn't", 'ma', 'mightn', "mightn't", 'mustn', "mustn't", 'needn', "needn't", 'shan', "shan't", 'shouldn', "shouldn't", 'wasn', "wasn't", 'weren', "weren't", 'won', "won't", 'wouldn', "wouldn't"]

def remove_stopwords(text, remove_stop=True):
  output = ""
  if remove_stop:
    text=text.split(" ")
    for word in text:
      if word not in stop_words:
        output=output + " " + word
  else :
    output=text

  return str(output.strip())

#Removing Stopwords from Training Data
processed_train_data = []
for line in train["comment_text"]:
    processed_train_data.append(remove_stopwords(line))

#Removing Stopwords from Test Data
processed_test_data = []
for line in test["comment_text"]:
    processed_test_data.append(remove_stopwords(line))

train["comment_text"] = processed_train_data
test["comment_text"] = processed_test_data
train.head()

"""Tokenization"""

CATEGORIES = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']

X_train = train["comment_text"]
y_train = train[CATEGORIES].values
X_test = test['comment_text']
y_test = test[CATEGORIES].values
X_train

class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
y_train_df = pd.DataFrame(y_train, columns=class_names)

for col in class_names:
  print(y_train_df[col].value_counts())
  print('\n')

"""Tokenization and Padding the sequence"""

from keras.preprocessing.text import Tokenizer
from keras.utils import pad_sequences

max_features=100000
maxpadlen = 500

tokenizer = Tokenizer(num_words=max_features,oov_token='<nothing>')
tokenizer.fit_on_texts(X_train)

def tokenization(data):
  data = tokenizer.texts_to_sequences(data)
  data=pad_sequences(data, maxlen=maxpadlen, padding = 'post')
  return data

X_train = tokenization(X_train)
X_test = tokenization(X_test)

"""Saving the toekenization"""

import pickle

# saving
with open('tokenizer.pickle', 'wb') as handle:
    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)

"""Loading the toekenizer. Note: First upload it to the files"""

# loading
with open('tokenizer.pickle', 'rb') as handle:
    tokenizer = pickle.load(handle)

"""Initaialing the word embedding using Sentence Transformer

Importing sentence transformer
"""

# !pip install sentence-transformers

# from sentence_transformers import SentenceTransformer

# model_name = 'all-MiniLM-L6-v2'
# sentence_transformer_model = SentenceTransformer(model_name)

# Converting sequences back to sentences
# sentences = tokenizer.sequences_to_texts(X_train)

# Obtaining sentence embeddings using the Sentence Transformer model
# sentence_embeddings = sentence_transformer_model.encode(sentences)

"""Saving the sentence_embedding in drive"""

# df_embeddings = pd.DataFrame(sentence_embeddings)
# df_embeddings.to_csv('/content/drive/MyDrive/Colab Notebooks/sentence_embeddings.csv', index=False)

# type(sentence_embeddings)

"""Directly load the embedded sentences"""

loaded_df_embeddings = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/sentence_embeddings.csv')
sentence_embeddings = loaded_df_embeddings.values

import tensorflow
from keras.models import Model
from keras.layers import *
from keras.utils import plot_model

"""defining function for evaluation"""

from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt

def threshold_calculation(class_names, y_test_df, y_pred_df):
  best_threshold = []
  fig, axs = plt.subplots(2, 3, figsize=(10, 5))

  for i, col in enumerate(class_names):
    precision, recall, thresholds = precision_recall_curve(y_test_df[col], y_pred_df[col])
    # Calculating F1-score for each threshold
    f1_scores = 2 * (precision * recall) / (precision + recall)
    # Find the index of the threshold that maximizes the F1-score
    best_threshold.append(thresholds[np.argmax(f1_scores)])
    ax = axs[i // 3, i % 3]
    ax.plot(recall, precision, color='b', label='Precision-Recall curve')
    ax.set_xlabel('Recall')
    ax.set_ylabel('Precision')
    ax.set_title(f'Precision-Recall Curve for {col}')
    ax.legend(loc='lower left')

  plt.tight_layout()
  plt.show()
  plt.savefig('precision_recall.png')

  return best_threshold

def convert_to_binary_predictions(y_pred_df, thresholds):
    binary_predictions_df = y_pred_df.copy()
    for i, col in enumerate(y_pred_df.columns):
        binary_predictions_df[col] = (y_pred_df[col] >= thresholds[i]).astype(int)
    return binary_predictions_df

def overall_eval(y_test, y_pred):
  class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
  y_test_df = pd.DataFrame(y_test, columns=class_names)
  y_pred_df = pd.DataFrame(y_pred, columns=class_names)

  best_threshold = threshold_calculation(class_names, y_test_df, y_pred_df)

  y_pred = convert_to_binary_predictions(y_pred_df, best_threshold).to_numpy()

  y_true_flat = y_test.ravel()
  y_pred_flat = y_pred.ravel()
  accuracy = accuracy_score(y_true_flat, y_pred_flat)
  f1 = f1_score(y_true_flat, y_pred_flat, average='weighted')
  recall = recall_score(y_true_flat, y_pred_flat, average='weighted')
  precision = precision_score(y_true_flat, y_pred_flat, average='weighted')

  return accuracy, f1, recall, precision, best_threshold

from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# for individuals levels
def evaluation(prediction, actual, col):
  accuracy = accuracy_score(actual[col], prediction[col])
  f1 = f1_score(actual[col], prediction[col], average='weighted')
  recall = recall_score(actual[col], prediction[col], average='weighted')
  precision = precision_score(actual[col], prediction[col], average='weighted')

  print("Accuracy of ",col , " is: " ,accuracy)
  print("F1-score of",col , " is: " ,f1)
  print("Recall of",col , " is: " ,recall)
  print("Precision of",col , " is: " ,precision)

# Plot the confusion matrix
def plot_confusion(prediction, actual, col):
  cm = confusion_matrix(actual[col], prediction[col])
  classes = [col]
  plt.figure(figsize=(4, 2))
  sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
  plt.xlabel('Predicted Labels')
  plt.ylabel('True Labels')
  plt.title('Confusion Matrix of '+ col)
  plt.show()

num_classes = 6
epochs = 10
batch_size = 128

"""Function for defining LSTM model"""

def lstmModel():
  inp=Input(shape=(maxpadlen, ),dtype='int32')
  embedding_layer = Embedding(input_dim=sentence_embeddings.shape[0],  # Number of words in the vocabulary
                            output_dim=sentence_embeddings.shape[1],  # Size of the embeddings
                            weights=[sentence_embeddings],  # Use the loaded embeddings
                            input_length=maxpadlen,
                            trainable=False)  # Freeze the embeddings
  embedded_sequences = embedding_layer(inp)
  x = LSTM(50, return_sequences=True,name='lstm_layer')(embedded_sequences)
  x = GlobalMaxPool1D()(x)
  x = Dropout(0.2)(x)
  x = Dense(40, activation="relu", kernel_initializer='he_uniform')(x)
  x = Dropout(0.2)(x)
  preds = Dense(6, activation="sigmoid", kernel_initializer='glorot_uniform')(x)

  #Compile the Model.
  lstm_model = Model(inputs=inp, outputs=preds)

  lstm_model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
  return lstm_model

model = lstmModel()

model.summary()

plot_model(model, show_shapes=True)

# Training the LSTM model

import mlflow.keras

mlflow.end_run()
def train_model(model, name):
  with mlflow.start_run():
    mlflow.keras.autolog()
    history = model.fit(X_train,y_train, epochs=epochs, batch_size=batch_size,  validation_split = 0.2)
    # model.save('/content/drive/MyDrive/Colab Notebooks/Toxic_comments_models/' + name)
    y_pred = model.predict(X_test)
    # y_pred_labels = (y_pred > threshold).astype(int)

    accuracy, f1, recall, precision, best_threshold = overall_eval(y_test, y_pred)
    # accuracy, f1, recall, precision, overall_auc = overal_eval(y_test, y_pred)

    mlflow.log_param("Model", name)
    mlflow.log_metric("Accuracy", accuracy)
    mlflow.log_metric("F1_score", f1)
    mlflow.log_metric("Recall", recall)
    mlflow.log_metric("Precision", precision)
    # mlflow.log_metric("Overall AUC", overall_auc)
    mlflow.log_artifact('precision_recall.png')
    plt.close()

  return history, best_threshold

history, best_threshold = train_model(model, "LSTM model")

best_threshold

"""Plotting train vs test"""

def plot_graph(history):
  plt.plot(history.history["accuracy"], label = "accuracy")
  plt.plot(history.history["val_accuracy"], label = "val_accuracy")
  plt.title("ACCURACY")
  plt.legend()
  plt.show()
  plt.plot(history.history["loss"], label = "loss")
  plt.plot(history.history["val_loss"], label = "val_loss")
  plt.title("LOSS")
  plt.legend()
  plt.show()

plot_graph(history)

"""Individual Level evaluations

"""

y_pred = model.predict(X_test)
class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
y_test_df = pd.DataFrame(y_test, columns=class_names)
y_pred_df = pd.DataFrame(y_pred, columns=class_names)

best_threshold = threshold_calculation(class_names, y_test_df, y_pred_df)

y_pred = convert_to_binary_predictions(y_pred_df, best_threshold)

for col in class_names:
    evaluation(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

for col in class_names:
    plot_confusion(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

best_threshold

"""Making predictions"""

input_text = "you are a stupid"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
model.predict(input_text)

"""Loading saved model from mlflow"""

# keras_model = mlflow.keras.load_model("dbfs:/databricks/mlflow-tracking/287377935647537/ad1711f885c34bc3bdf11daf54b1b4a5/artifacts/model")

"""Creating a Bidirectional LSTM model

"""

from keras.layers import Bidirectional

def BilstmModel():
  inp=Input(shape=(maxpadlen, ),dtype='int32')
  embedding_layer = Embedding(input_dim=sentence_embeddings.shape[0],  # Number of words in the vocabulary
                            output_dim=sentence_embeddings.shape[1],  # Size of the embeddings
                            weights=[sentence_embeddings],  # Use the loaded embeddings
                            input_length=maxpadlen,
                            trainable=False)  # Freeze the embeddings
  embedded_sequences = embedding_layer(inp)
  x = Bidirectional(LSTM(50, return_sequences=True,name='lstm_layer'))(embedded_sequences)
  x = GlobalMaxPool1D()(x)
  x = Dropout(0.2)(x)
  x = Dense(40, activation="relu", kernel_initializer='he_uniform')(x)
  x = Dropout(0.2)(x)
  preds = Dense(6, activation="sigmoid", kernel_initializer='glorot_uniform')(x)

  #Compile the Model.
  bilstm_model = Model(inputs=inp, outputs=preds)

  bilstm_model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
  return bilstm_model

model = BilstmModel()

model.summary()

plot_model(model, show_shapes=True)

history,best_threshold = train_model(model, "Bidirectional LSTM model")

plot_graph(history)

best_threshold

y_pred = model.predict(X_test)
class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
y_test_df = pd.DataFrame(y_test, columns=class_names)
y_pred_df = pd.DataFrame(y_pred, columns=class_names)

best_threshold = threshold_calculation(class_names, y_test_df, y_pred_df)

y_pred = convert_to_binary_predictions(y_pred_df, best_threshold)

for col in class_names:
    evaluation(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

for col in class_names:
    plot_confusion(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

"""Defining BiLSTM+CNN model"""

def Bilstm_CNNModel():
  inp=Input(shape=(maxpadlen, ),dtype='int32')
  embedding_layer = Embedding(input_dim=sentence_embeddings.shape[0],  # Number of words in the vocabulary
                              output_dim=sentence_embeddings.shape[1],  # Size of the embeddings
                              weights=[sentence_embeddings],  # Use the loaded embeddings
                              input_length=maxpadlen,
                              trainable=False)  # Freeze the embeddings
  embedded_sequences = embedding_layer(inp)
  x = Bidirectional(LSTM(50, return_sequences=True,name='lstm_layer'))(embedded_sequences)
  x = Conv1D(filters=64, kernel_size=3, padding='same', activation='relu', kernel_initializer='he_uniform')(x)
  # x = MaxPooling1D(3)(x)
  x = GlobalMaxPool1D()(x)
  # x = BatchNormalization()(x)
  x = Dropout(0.2)(x)
  x = Dense(40, activation="relu", kernel_initializer='he_uniform')(x)
  x = Dropout(0.2)(x)
  x = Dense(30, activation="relu", kernel_initializer='he_uniform')(x)
  x = Dropout(0.2)(x)
  preds = Dense(6, activation="sigmoid", kernel_initializer='glorot_uniform')(x)

  #Compile the Model.
  combined_model = Model(inputs=inp, outputs=preds)

  combined_model.compile(loss='binary_crossentropy',
                  optimizer='adam',
                  metrics=['accuracy'])
  return combined_model

model = Bilstm_CNNModel()

model.summary()

plot_model(model, show_shapes=True)

history, best_threshold = train_model(model, "Combined model")

best_threshold

plot_graph(history)

y_pred = model.predict(X_test)
class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
y_test_df = pd.DataFrame(y_test, columns=class_names)
y_pred_df = pd.DataFrame(y_pred, columns=class_names)

best_threshold = threshold_calculation(class_names, y_test_df, y_pred_df)

y_pred = convert_to_binary_predictions(y_pred_df, best_threshold)

for col in class_names:
    evaluation(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

for col in class_names:
    plot_confusion(prediction=y_pred, actual=y_test_df, col=col)
    print('\n')

# best_model = mlflow.keras.load_model("dbfs:/databricks/mlflow-tracking/287377935647537/feab5c8f662a4de880ac55a87591520b/artifacts/model")
# best_model.save('/content/drive/MyDrive/Colab Notebooks/Toxic_comments_models/BiLSTM')

# biLSTM_threshold = [0.65397644, 0.84165853, 0.55169016, 0.14203131, 0.4851602, 0.23365118]

# loaded = tf.keras.models.load_model("/content/drive/MyDrive/Colab Notebooks/Toxic_comments_models/BiLSTM")

best_model = mlflow.keras.load_model("dbfs:/databricks/mlflow-tracking/287377935647537/82a770a9461b4089a94a25c0c52ad1f7/artifacts/model")
best_model.save('/content/drive/MyDrive/Colab Notebooks/Toxic_comments_models/combined')

combined_threshold = [0.5553138, 0.70162964, 0.5837073, 0.16264592, 0.45770496, 0.24438907]
bi_threshold = [0.65397644, 0.84165853, 0.55169016, 0.14203131, 0.4851602, 0.23365118]

input_text = "Hi! I am back again! Last warning! Stop undoing my edits or die!"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
best_model.predict(input_text)

input_text = "You are an asshole. You dont deserve to live. Idiot"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
best_model.predict(input_text)

input_text = "You go and die"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
best_model.predict(input_text)

bi_model = mlflow.keras.load_model("dbfs:/databricks/mlflow-tracking/287377935647537/feab5c8f662a4de880ac55a87591520b/artifacts/model")

input_text = "You go and die"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
print(bi_model.predict(input_text))

input_text = "You are an asshole. You dont deserve to live. Idiot"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
print(bi_model.predict(input_text))

input_text = "Hi! I am back again! Last warning! Stop undoing my edits or die!"
processed_input_text = []
processed_input_text.append(remove_stopwords(input_text))
input_text = tokenization(processed_input_text)
input_text
print(bi_model.predict(input_text))

def convert_to_binary(y_pred, thresholds):
    class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']
    y_pred_df = pd.DataFrame(y_pred, columns=class_names)
    binary_predictions_df = y_pred_df.copy()
    for i, col in enumerate(y_pred_df.columns):
        binary_predictions_df[col] = (y_pred_df[col] >= thresholds[i]).astype(int)
    return binary_predictions_df

input_text = ["You go and die", "You are an asshole. You dont deserve to live. Idiot", "Hi! I am back again! Last warning! Stop undoing my edits or die!", "Thank you for your help", "I am Sorry"]
processed_input_text = []
for item in input_text:
  processed_input_text.append(remove_stopwords(item))
input_text = tokenization(processed_input_text)

"""Inference using BiLSTM model"""

pred = bi_model.predict(input_text)
print(convert_to_binary(pred, bi_threshold))

"""Inference using Combined model"""

pred = best_model.predict(input_text)
print(convert_to_binary(pred, combined_threshold))

input_text = ["Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!",
              "A pair of jew-hating weiner nazi schmucks.",
              "this user is such a worthless goddamn faggot fuck you faggot",
              "Well you are ridiculous, in fact I suspect that you are Calton, please block me, I dont care....",
              "Thanks, and I apologize for my comment.  I'd like you to know that I understand your position.   16:33, 7 Nov 2004 (UTC)"]
processed_input_text = []
for item in input_text:
  processed_input_text.append(remove_stopwords(item))
input_text = tokenization(processed_input_text)

pred = bi_model.predict(input_text)
print("BiLSTM model prediction")
print(convert_to_binary(pred, bi_threshold))

pred = best_model.predict(input_text)
print("Combined model prediction")
print(convert_to_binary(pred, combined_threshold))

# saving
with open('biLSTM.pickle', 'wb') as handle:
    pickle.dump(bi_model, handle, protocol=pickle.HIGHEST_PROTOCOL)

with open('combined.pickle', 'wb') as handle:
    pickle.dump(best_model, handle, protocol=pickle.HIGHEST_PROTOCOL)

